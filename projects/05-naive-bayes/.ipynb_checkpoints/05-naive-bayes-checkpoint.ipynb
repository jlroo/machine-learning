{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies Review - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find two files there (one with positive and one with negative reviews).\n",
    "\n",
    "### Naive Bayes Implementation\n",
    "* Implement your own version of the Naive Bayes Classifier. Your task is to build a binary classifier that will perform movie review classification.\n",
    "\n",
    "### Data Transformation\n",
    "* Convert each example into a vector. You will likely end up with feature vectors of very high dimensionality. \n",
    "* keep only 10 most frequent words and/or remove all words that occur only in a single example). I\n",
    "* Remove stop words from the data\n",
    "\n",
    "### Tasks\n",
    "* split your data into training (70%), development (15%) and test (15%)\n",
    "* Tune your classifier on the development set and evaluate on the test set. \n",
    "* evaluation metric.\n",
    "\n",
    "Include the details on what kind of pre-processing you performed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBClassifier:\n",
    "    \n",
    "    \"\"\"\n",
    "    Usage Example:\n",
    "    \n",
    "    X = np.array([[1,0,1,1],\n",
    "                 [1,1,0,0],\n",
    "                 [1,0,2,1],\n",
    "                 [0,1,1,1],\n",
    "                 [0,0,0,0]]);\n",
    "    y = np.array([0,1,1,1,0,1,0,1])\n",
    "    x_test = np.array([[1,0,1,0],[0,0,0,1]])\n",
    "    \n",
    "    clf = NBClassifier()\n",
    "    clf.fit(X,y)\n",
    "    clf.predict(x_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, priors=None, probabilities = False):\n",
    "        self.probs = probabilities\n",
    "        if priors:\n",
    "            self.priors = priors\n",
    "        \n",
    "    def _priors(self, target):\n",
    "        n_target = len(target)\n",
    "        self.priors = dict(Counter(target))\n",
    "        for k in self.priors.keys():\n",
    "            self.priors[k] = self.priors[k]/float(n_target)\n",
    "        return self.priors\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._X=X\n",
    "        self._y=y\n",
    "        self._classes = np.unique(self._y)\n",
    "        features = self._X.shape[1]\n",
    "        self._likelihoods = {i:defaultdict(list) for i in self._classes} \n",
    "\n",
    "        self._classes_proba = self._priors(self._y)\n",
    "\n",
    "        for cls in self._classes:\n",
    "            idx_class = np.where(self._y == cls)[0]\n",
    "            X_subset = self._X[idx_class, :]\n",
    "            for i in range(X_subset.shape[1]):\n",
    "                self._likelihoods[cls][i] += list(X_subset[:,i])\n",
    "                \n",
    "        for cls in self._classes:\n",
    "            for i in range(features):\n",
    "                 self._likelihoods[cls][i] = self._priors(self._likelihoods[cls][i])\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        self.pred = np.empty(shape=(X.shape[0],0),dtype = self._y.dtype)\n",
    "        results = {}\n",
    "        for i in range(X_pred.shape[0]):\n",
    "            for cls in self._classes:\n",
    "                cls_proba = self._classes_proba[cls]\n",
    "                for k in range(X_pred[i].shape[0]):\n",
    "                    _feature_proba = self._likelihoods[cls][k]\n",
    "                    if X_pred[i][k] in self._classes_proba.keys():\n",
    "                        cls_proba *= _feature_proba[X_pred[i][k]]\n",
    "                    else:\n",
    "                        cls_proba *= 0\n",
    "                    results[cls] = cls_proba\n",
    "            if self.probs:\n",
    "                self.pred = np.append(self.pred, max(results.values()))\n",
    "            else:\n",
    "                dd = {v[1]:v[0] for v in results.items()}\n",
    "                self.pred = np.append(self.pred, dd[max(dd.keys())])\n",
    "        return self.pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(messages, stop_words = ['english'], max_features = None):\n",
    "    corpus = [re.sub(r\"\\b\\d+\\b|![:alpha:]|\\d|\\W|_|\\b\\w{1,2}\\b\", \" \", m).lower() for m in messages]\n",
    "    if max_features is not None:\n",
    "        vectorizer = CountVectorizer(strip_accents = 'ascii', \n",
    "                                     stop_words=stop_words, \n",
    "                                     max_features = max_features)\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(strip_accents = 'ascii', \n",
    "                                     stop_words=stop_words_list)\n",
    "    vcorpus = vectorizer.fit_transform(corpus)\n",
    "    labels = vectorizer.get_feature_names()\n",
    "    return vcorpus.toarray(), labels\n",
    "\n",
    "def data_preparation(pos_reviews, neg_reviews,file_out = False):\n",
    "    neg_reviews[\"class_label\"] = 0\n",
    "    neg_reviews.columns = [\"review\",\"class_label\"]\n",
    "    pos_reviews[\"class_label\"] = 1\n",
    "    pos_reviews.columns = [\"review\",\"class_label\"]\n",
    "    reviews = pd.concat([pos_reviews, neg_reviews],axis=0)\n",
    "    if file_out:\n",
    "        reviews.to_csv(\"data/reviews.csv\",index=False)\n",
    "    return reviews\n",
    "\n",
    "def data_split(X,y,splits = [0.3,0.5]):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size = splits[0], \n",
    "                                                        random_state=1)\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, \n",
    "                                                    test_size = splits[1], \n",
    "                                                    random_state=1)\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews = pd.read_csv(\"data/neg-rt-polarity.txt\", sep=\"\\n\", header=None)\n",
    "pos_reviews = pd.read_csv(\"data/pos-rt-polarity.txt\", sep=\"\\n\", header=None)\n",
    "reviews = data_preparation(pos_reviews, neg_reviews, file_out = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, labels = text_processing(reviews['review'],max_features=100)\n",
    "y = np.array(reviews['class_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split: Train (70%), development (15%) and test (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test = data_split(X, y, splits = [0.3,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5743088768867185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_dev)\n",
    "f1_score(y_pred = pred, y_true = y_dev, average='weighted')\n",
    "# 10 - 0.5373\n",
    "# 100 - 0.5743"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn - Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model prediction - dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61905910063885405"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_dev)\n",
    "f1_score(y_pred = pred, y_true = y_dev, average='weighted')\n",
    "# 10 - 0.5487\n",
    "# 100 - 0.6190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model prediction - test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61857126113455219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "f1_score(y_pred = pred, y_true = y_test, average='weighted')\n",
    "# 10 - 0.5472\n",
    "# 100 - 0.6185"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62296095908115023"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.001)\n",
    "cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean()\n",
    "# 10 - 0.55862072300342358\n",
    "# 100 - 0.6229"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
